{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Linear Map with Uniform Sampling\n",
    "([From BET Documentation](http://ut-chg.github.io/BET/examples/example_rst_files/validation.html#validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will walk through the following [example](linearMap.py). This 2D linear example shows that geometrically distinct QoI can recreate a probability measure on the input parameter space used to define the output probability measure. The user can explore various discretization effects.\n",
    "\n",
    "1D and 2D marginals are calculated, smoothed, and plotted. The actual process is quite simple requiring a total of 5 steps to solve the stochastic inverse problem with BET excluding any post-processing the user may want. The most complicated part of this problem is Step (4) defining the user distribution on the data space from propagated samples. In general the user will probably not write code with various options as was done here for pedagogical purposes. \n",
    "\n",
    "We break down the actual example included with BET step-by-step below, but first, to showcase the overall simplicitly, we show the “entire” code (omitting setting the environment, post-processing, and commenting) required for solving the stochastic inverse problem using some default options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sampler = bsam.sampler(my_model)\n",
    "\n",
    "input_samples = samp.sample_set(2)\n",
    "input_samples.set_domain(np.repeat([[0.0, 1.0]], 2, axis=0))\n",
    "input_samples = sampler.regular_sample_set(input_samples, num_samples_per_dim=[30, 30])\n",
    "input_samples.estimate_volume_mc()\n",
    "\n",
    "my_discretization = sampler.compute_QoI_and_create_discretization(input_samples)\n",
    "\n",
    "num_samples_discretize_D = 10\n",
    "num_iid_samples = 1E5\n",
    "Partition_set = samp.sample_set(2)\n",
    "Monte_Carlo_set = samp.sample_set(2)\n",
    "Partition_set.set_domain(np.repeat([[0.0, 1.0]], 2, axis=0))\n",
    "Monte_Carlo_set.set_domain(np.repeat([[0.0, 1.0]], 2, axis=0))\n",
    "Partition_discretization = sampler.create_random_discretization('random',\n",
    "                                                        Partition_set,\n",
    "                                                        num_samples=num_samples_discretize_D)\n",
    "Monte_Carlo_discretization = sampler.create_random_discretization('random',\n",
    "                                                        Monte_Carlo_set,\n",
    "                                                        num_samples=num_iid_samples)\n",
    "simpleFunP.user_partition_user_distribution(my_discretization,\n",
    "                                        Partition_discretization,\n",
    "                                        Monte_Carlo_discretization)\n",
    "\n",
    "calculateP.prob(my_discretization)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (0): Setting up the environment\n",
    "Import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bet.calculateP.simpleFunP as simpleFunP\n",
    "import bet.calculateP.calculateP as calculateP\n",
    "import bet.postProcess.plotP as plotP\n",
    "import bet.postProcess.plotDomains as plotD\n",
    "import bet.sample as samp\n",
    "import bet.sampling.basicSampling as bsam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (1): Define the interface to the model\n",
    "\n",
    "Import the Python script interface to the (simple Python) [model](myModel.py) that takes as input a numpy array of model input parameter samples, generated from the sampler (see below), evaluates the model to generate QoI samples, and returns the QoI samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from myModel import my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the sampler that will be used to create the discretization object, which is the fundamental object used by BET to compute solutions to the stochastic inverse problem. The sampler and my_model is the interface of BET to the model, and it allows BET to create input/output samples of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampler = bsam.sampler(my_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (2): Describe and sample input space\n",
    "Initialize the (2-dimensional) input parameter sample set object and set the parameter domain to be a unit-square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_samples = samp.sample_set(2)\n",
    "input_samples.set_domain(np.repeat([[0.0, 1.0]], 2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested changes for user exploration (1):\n",
    "Try with and without random sampling.\n",
    "\n",
    "If using **random** sampling, try:\n",
    "* Setting `num_samples = 1E3` and `num_samples = 1E4` \n",
    "* See what happens when `num_samples = 1E2`\n",
    "* Using `'lhs'` instead of `'random'` in the `random_sample_set`\n",
    "\n",
    "If using **regular** sampling, try different numbers of samples per dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "randomSampling = False\n",
    "if randomSampling is True:\n",
    "    input_samples = sampler.random_sample_set('random', input_samples, num_samples=1E3)\n",
    "else:\n",
    "    input_samples = sampler.regular_sample_set(input_samples, num_samples_per_dim=[30, 30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested changes for user exploration (2):\n",
    "A standard Monte Carlo (MC) assumption is that every Voronoi cell has the same volume. If a regular grid of samples was used, then the standard MC assumption is true.\n",
    "\n",
    "See what happens if the MC assumption is not assumed to be true, and if different numbers of points are used to estimate the volumes of the Voronoi cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MC_assumption = True\n",
    "if MC_assumption is False:\n",
    "    input_samples.estimate_volume(n_mc_points=1E5)\n",
    "else:\n",
    "    input_samples.estimate_volume_mc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (3): Generate QoI samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the discretization object holding all the input (parameter) samples and output (QoI) samples using the sampler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_discretization = sampler.compute_QoI_and_create_discretization(input_samples,\n",
    "                                           savefile = 'Validation_discretization.txt.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, all of the model information has been extracted for BET, so the model is no longer required for evaluation. The user could do Steps (0)-(3) in a separate script, and then simply load the discretization object as part of a separate BET script that does the remaining steps. When the model is expensive to evaluate, this is an attractive option since we can now solve the stochastic inverse problem (with many different distributions defined on the data space) without ever having to re-solve the model (so long as we are happy with the resolution provided by the current discretization of the parameter and data spaces)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (4): Describe the data distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem is nominally a “parameter distribution estimation” problem and not a “parameter identification under uncertainty” problem (e.g., see [Example: Linear Map with Uniform Sampling](../linearMap/LinearMapExample.ipynb) or almost any of the other examples). Thus, unlike most other examples, the distribution on data space is not coming from uncertain data but rather variable input parameters that vary according to a fixed distribution. The goal is to determine this distribution by inverting the observed distribution on the data space (via discretizing the data space and binning samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suggested changes for user exploration (3):\n",
    "Compute the output distribution simple function approximation by propagating a different set of samples to implicitly define a Voronoi discretization of the data space, corresponding to an implicitly defined set of contour events defining a discretization of the input parameter space. The probabilities of the Voronoi cells in the data space (and thus the probabilities of the corresponding contour events in the input parameter space) are determined by Monte Carlo sampling using a set of i.i.d. uniform samples to bin into these cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* See the effect of using different values for `num_samples_discretize_D`. \n",
    "\n",
    "* Choosing `num_samples_discretize_D = 1` produces exactly the right answer and is equivalent to assigning a uniform probability to each data sample above (why?). \n",
    "\n",
    "* Try setting this to 2, 5, 10, 50, and 100. Can you explain what you are seeing? \n",
    "\n",
    "* To see an exaggerated effect, try using random sampling above with `n_samples` set to `1E2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_discretize_D = 1\n",
    "num_iid_samples = 1E5\n",
    "\n",
    "Partition_set = samp.sample_set(2)\n",
    "Monte_Carlo_set = samp.sample_set(2)\n",
    "\n",
    "Partition_set.set_domain(np.repeat([[0.0, 1.0]], 2, axis=0))\n",
    "Monte_Carlo_set.set_domain(np.repeat([[0.0, 1.0]], 2, axis=0))\n",
    "\n",
    "Partition_discretization = sampler.create_random_discretization('random',\n",
    "                                                            Partition_set,\n",
    "                                                            num_samples=num_samples_discretize_D)\n",
    "\n",
    "Monte_Carlo_discretization = sampler.create_random_discretization('random',\n",
    "                                                            Monte_Carlo_set,\n",
    "                                                            num_samples=num_iid_samples)\n",
    "\n",
    "simpleFunP.user_partition_user_distribution(my_discretization,\n",
    "                                            Partition_discretization,\n",
    "                                            Monte_Carlo_discretization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (5): Solve the stochastic inverse problem\n",
    "Calculate probablities on the parameter space (which are stored within the discretization object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculateP.prob(my_discretization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step (6) [Optional]: Post-processing\n",
    "Show some plots of the different sample sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plotD.scatter_2D(my_discretization._input_sample_set, filename = 'Parameter_Samples.svg')\n",
    "plotD.scatter_2D(my_discretization._output_sample_set, filename = 'QoI_Samples.svg')\n",
    "plotD.scatter_2D(my_discretization._output_probability_set, filename = 'Data_Space_Discretization.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to refresh html after changes within notebook\n",
    "import random\n",
    "__counter__ = random.randint(0,2e9)\n",
    "\n",
    "# displays 1D marginal probabilities\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table>\"+\n",
    "             \"<tr><td><center>Parameter Samples</center><img src='Parameter_Samples.svg?%d'></td>\"% __counter__+\n",
    "             \"<td><center>QoI Samples</center><img src='QoI_Samples.svg?%d'></td></tr>\"% __counter__+\n",
    "             \"<tr><td><center>Data Space Discretization</center><img src='Data_Space_Discretization.svg?%d'></td>\"% __counter__+\n",
    "             \"<td></td></tr>\"+\n",
    "             \"</table>\" ))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are ways to determine “optimal” smoothing parameters (e.g., see CV, GCV, and other similar methods), but we have not incorporated these into the code as lower-dimensional marginal plots generally have limited value in understanding the structure of a high dimensional non-parametric probability measure.\n",
    "\n",
    "The user may want to change `nbins` or `sigma` in the `plotP.*` inputs (which influences the kernel density estimation with smaller values of `sigma` implying a density estimate that looks more like a histogram and larger values smoothing out the values more).\n",
    "\n",
    "In general, the user will have to tune these for any given problem especially when looking at marginals of higher-dimensional problems with parameter ranges that have disparate scales (assuming the parameters were not first normalized as part of a “un-dimensionalization” of the space, which is highly encouraged):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate 2d marginal probs\n",
    "(bins, marginals2D) = plotP.calculate_2D_marginal_probs(input_samples,\n",
    "                                                        nbins = [30, 30])\n",
    "\n",
    "# plot 2d marginals probs\n",
    "plotP.plot_2D_marginal_probs(marginals2D, bins, input_samples, filename = \"validation_raw\",\n",
    "                             file_extension = \".svg\", plot_surface=False)\n",
    "\n",
    "# smooth 2d marginals probs (optional)\n",
    "marginals2D = plotP.smooth_marginals_2D(marginals2D, bins, sigma=0.1)\n",
    "\n",
    "# plot 2d marginals probs\n",
    "plotP.plot_2D_marginal_probs(marginals2D, bins, input_samples, filename = \"validation_smooth\",\n",
    "                             file_extension = \".svg\", plot_surface=False)\n",
    "\n",
    "# calculate 1d marginal probs\n",
    "(bins, marginals1D) = plotP.calculate_1D_marginal_probs(input_samples,\n",
    "                                                        nbins = [30, 30])\n",
    "\n",
    "# plot 1d marginal probs\n",
    "plotP.plot_1D_marginal_probs(marginals1D, bins, input_samples, filename = \"validation_raw\",\n",
    "                             file_extension = \".svg\")\n",
    "\n",
    "# smooth 1d marginal probs (optional)\n",
    "marginals1D = plotP.smooth_marginals_1D(marginals1D, bins, sigma=0.1)\n",
    "\n",
    "# plot 1d marginal probs\n",
    "plotP.plot_1D_marginal_probs(marginals1D, bins, input_samples, filename = \"validation_smooth\",\n",
    "                             file_extension = \".svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D Marginal Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to refresh html after changes within notebook\n",
    "import random\n",
    "__counter__ = random.randint(0,2e9)\n",
    "\n",
    "# displays 1D marginal probabilities\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table>\"+\n",
    "             \"<tr><td><center>Raw</center><img src='validation_raw_1D_0.svg?%d'></td>\"% __counter__+\n",
    "             \"<td><center>Raw</center><img src='validation_raw_1D_1.svg?%d'></td></tr>\"% __counter__+\n",
    "             \"<tr><td><center>Smooth</center><img src='validation_smooth_1D_0.svg?%d'></td>\"% __counter__+\n",
    "             \"<td><center>Smooth</center><img src='validation_smooth_1D_1.svg?%d'></td></tr>\"% __counter__+\n",
    "             \"</table>\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Marginial Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hack to refresh html after changes within notebook\n",
    "import random\n",
    "__counter__ = random.randint(0,2e9)\n",
    "\n",
    "# displays 1D marginal probabilities\n",
    "from IPython.display import HTML, display\n",
    "display(HTML(\"<table>\"+\n",
    "             \"<tr><td><center>Raw</center><img src='validation_raw_2D_0_1.svg?%d'></td>\"% __counter__+\n",
    "             \"<td><center>Smooth</center><img src='validation_smooth_2D_0_1.svg?%d'></td></tr>\"% __counter__+\n",
    "             \"</table>\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
