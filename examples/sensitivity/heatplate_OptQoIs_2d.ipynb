{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Title: Example Notebook Template\n",
    "Copyright (C) 2014-2019 The BET Development Team\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of example goes here. What are your motivations? Outline the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2014-2016 The BET Development Team\n",
    "\n",
    "\"\"\"\n",
    "Consider a thin 2-dimensional (square) metal plate constructed by welding\n",
    "together two rectangular metal plates of similar alloy types together.\n",
    "The alloy types differ due to variations in the manufacturing of the\n",
    "rectangular plates, so the thermal diffusivity is different on the left\n",
    "and right sides of the resulting square plate.\n",
    "We want to quantify uncertainties in these thermal diffusivities using\n",
    "the heat equation to model experiments where the square plates are subject\n",
    "to an external, localized, source at the center of the plate.\n",
    "Assuming we have exactly two contact thermometers with which to record\n",
    "exactly two temperature measurements during the experiment, the question\n",
    "is the following: what are the optimal placements of these thermometers\n",
    "in space-time?\n",
    "\n",
    "See the manuscript at http://arxiv.org/abs/1601.06702 for details involving\n",
    "this problem and the simulations used to generate the data in Section 5.1.\n",
    "Here, we take the simulated data from the model problem saved as *.mat files\n",
    "that contains parameter samples chosen in clusters around 16 random\n",
    "points in the input space, and the corresponding QoIs (data) from the points\n",
    "in space shown in Figure 6 of the manuscript at the 50 time steps of the\n",
    "simulation (resulting in 1000 total different possible QoIs to choose from\n",
    "in space-time).\n",
    "We use the clusters of samples to compute gradients of the QoI using either\n",
    "radial basis function, forward, or centered finite difference schemes.\n",
    "These gradients are used to compute the average skewness in the possible 2D maps.\n",
    "We then choose the optimal set of 2 QoIs to use in the inverse problem by\n",
    "minimizing average skewness.\n",
    "\"\"\"\n",
    "\n",
    "import scipy.io as sio\n",
    "import bet.sensitivity.gradients as grad\n",
    "import bet.sensitivity.chooseQoIs as cqoi\n",
    "import bet.Comm as comm\n",
    "import bet.sample as sample\n",
    "\n",
    "# Select the type of finite difference scheme as either RBF, FFD, or CFD\n",
    "fd_scheme = 'RBF'\n",
    "\n",
    "# Import the data from the FEniCS simulation (RBF or FFD or CFD clusters)\n",
    "if fd_scheme.upper() in ['RBF', 'FFD', 'CFD']:\n",
    "    file_name = 'heatplate_2d_16clusters' + fd_scheme.upper() + '_1000qoi.mat'\n",
    "    matfile = sio.loadmat(file_name)\n",
    "else:\n",
    "    print('no data files for selected finite difference scheme')\n",
    "    exit()\n",
    "\n",
    "# Select a subset of QoI to check for optimality\n",
    "'''\n",
    "In Figure 6 of the manuscript at http://arxiv.org/abs/1601.06702, we see\n",
    "that there are 20 spatial points considered and 50 time steps for a total\n",
    "of 1000 different QoI.\n",
    "The QoI are indexed so that the QoI corresponding to indices\n",
    "\n",
    "    (i-1)*20 to i*20\n",
    "\n",
    "for i between 1 and 50 corresponds to the 20 labeled QoI from Figure 6\n",
    "at time step i.\n",
    "\n",
    "Using this information, we can check QoI either across the entire range\n",
    "of all space-time locations (``indexstart = 0``, ``indexstop = 1000``), or,\n",
    "we can check the QoI at a particular time (e.g., setting ``indexstart=0`` and\n",
    "``indexstop = 20`` considers all the spatial QoI only at the first time step).\n",
    "\n",
    "In general, ``indexstart`` can be any integer between 0 and 998  and\n",
    "``indexstop`` must be at least 2 greater than ``indexstart`` (so between\n",
    "2 and 1000 subject to the additional constraint that ``indexstop``\n",
    ":math: `\\geq` ``indexstart + 2`` to ensure that we check at least a single pair\n",
    "of QoI.)\n",
    "'''\n",
    "indexstart = 0\n",
    "indexstop = 20\n",
    "qoiIndices = np.arange(indexstart, indexstop)\n",
    "\n",
    "# Initialize the necessary sample objects\n",
    "input_samples = sample.sample_set(2)\n",
    "output_samples = sample.sample_set(1000)\n",
    "\n",
    "# Set the input sample values from the imported file\n",
    "input_samples.set_values(matfile['samples'])\n",
    "\n",
    "# Set the data fromthe imported file\n",
    "output_samples.set_values(matfile['data'])\n",
    "\n",
    "# Create the cluster discretization\n",
    "cluster_discretization = sample.discretization(input_samples, output_samples)\n",
    "\n",
    "# Calculate the gradient vectors at each of the 16 centers for each of the\n",
    "# QoI maps\n",
    "if fd_scheme.upper() in ['RBF']:\n",
    "    center_discretization = grad.calculate_gradients_rbf(cluster_discretization,\n",
    "        normalize=False)\n",
    "elif fd_scheme.upper() in ['FFD']:\n",
    "    center_discretization = grad.calculate_gradients_ffd(cluster_discretization)\n",
    "else:\n",
    "    center_discretization = grad.calculate_gradients_cfd(cluster_discretization)\n",
    "\n",
    "input_samples_centers = center_discretization.get_input_sample_set()\n",
    "\n",
    "# Choose a specific set of QoIs to check the average skewness of\n",
    "index1 = 0\n",
    "index2 = 4\n",
    "(specific_skewness, _) = cqoi.calculate_avg_skewness(input_samples_centers,\n",
    "        qoi_set=[index1, index2])\n",
    "if comm.rank == 0:\n",
    "    print('The average skewness of the QoI map defined by indices ' + str(index1) + \\\n",
    "        ' and ' + str(index2) + ' is ' + str(specific_skewness))\n",
    "\n",
    "# Compute the skewness for each of the possible QoI maps determined by choosing\n",
    "# any two QoI from the set defined by the indices selected by the\n",
    "# ``indexstart`` and ``indexend`` values\n",
    "skewness_indices_mat = cqoi.chooseOptQoIs(input_samples_centers, qoiIndices,\n",
    "    num_optsets_return=10, measure=False)\n",
    "\n",
    "qoi1 = skewness_indices_mat[0, 1]\n",
    "qoi2 = skewness_indices_mat[0, 2]\n",
    "\n",
    "if comm.rank == 0:\n",
    "    print('The 10 smallest condition numbers are in the first column, the \\\n",
    "corresponding sets of QoIs are in the following columns.')\n",
    "    print(skewness_indices_mat[:10, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize Parameter Space\n",
    "\n",
    "Define the sampler that will be used to create the discretization\n",
    "object, which is the fundamental object used by BET to compute\n",
    "solutions to the stochastic inverse problem.\n",
    "The `sampler` and `my_model` is the interface of BET to the model,\n",
    "and it allows BET to create input/output samples of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Changes \n",
    "\n",
    "Try with and without random sampling.\n",
    "\n",
    "If using random sampling, try `num_samples = 1E3` and `1E4`.\n",
    "What happens when `num_samples = 1E2`?\n",
    "Try using `'lhs'` instead of `'random'` in the `random_sample_set`.\n",
    "\n",
    "If using regular sampling, try different numbers of samples\n",
    "per dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize Data Space\n",
    "Compute the output distribution simple function approximation by\n",
    "propagating a different set of samples to implicitly define a Voronoi\n",
    "discretization of the data space, corresponding to an implicitly defined\n",
    "set of contour events defining a discretization of the input parameter\n",
    "space. \n",
    "\n",
    "The probabilities of the Voronoi cells in the data space (and\n",
    "thus the probabilities of the corresponding contour events in the\n",
    "input parameter space) are determined by Monte Carlo sampling using\n",
    "a set of i.i.d. uniform samples to bin into these cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested Changes\n",
    "\n",
    "A standard Monte Carlo (MC) assumption is that every Voronoi cell\n",
    "has the same volume. If a regular grid of samples was used, then\n",
    "the standard MC assumption is true.\n",
    "\n",
    "See what happens if the MC assumption is not assumed to be true, and\n",
    "if different numbers of points are used to estimate the volumes of\n",
    "the Voronoi cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove all Files (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.txt.gz.mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
