{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Linear Sensitivity Examples\n",
    "Copyright (C) 2014-2019 The BET Development Team\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we consider a simple example where a parameter space is given by a 5-dimensional hypercube and the goal is to choose an optimal QoI map from a space of possible QoI maps, denoted by $\\mathcal{Q}$, where each QoI map is linear.\n",
    "We use this simple example to demonstrate the use of the code to optimally choose which possible QoI map does the best job of \"scaling\" inverse sets to smaller sets.\n",
    "\n",
    "The idea is that if we generally consider a set of high probability in a particular data space defined by the range of a QoI map, we would prefer that the inverse of this set is as small as possible in order to try and identify the parameter responsible for the data.\n",
    "This only makes sense for stochastic inverse problems framed within the context of parameter identification under uncertainty.\n",
    "\n",
    "In other words, when the problem is that the data are uncertain due to measurement uncertainty and there is a true/exact parameter responsible for whichever uncertain data is observed, then this is the type of problem for which this optimization criteria is most appropriate.\n",
    "\n",
    "This set of examples generates uniform random samples in the unit n-dimensional hypercube and corresponding QoIs (data) generated by a linear map $Q$.\n",
    "We then calculate thegradients using an RBF scheme and use the gradient information to choose the optimal set of 2 (3, 4, ... `input_dim`) QoIs to use in the inverse problem.\n",
    "\n",
    "Every real world problem requires special attention regarding how we choose *optimal QoIs*.  This set of examples (examples/sensitivity/linear) covers some of the more common scenarios using easy to understand linear maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bet.sensitivity.gradients as grad\n",
    "import bet.sensitivity.chooseQoIs as cqoi\n",
    "import bet.calculateP.simpleFunP as simpleFunP\n",
    "import bet.calculateP.calculateP as calculateP\n",
    "import bet.postProcess.postTools as postTools\n",
    "import bet.Comm as comm\n",
    "import bet.sample as sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Methods\n",
    "The following executes code that is shared by all three `linear` examples, allowing us to avoid copy/pasting the same functions in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_problem(input_dim, output_dim, num_samples=1E5, num_centers=10):\n",
    "    # Let the map Q be a random matrix of size (output_dim, input_dim)\n",
    "#     np.random.seed(0)\n",
    "    Q = np.random.random([output_dim, input_dim])\n",
    "\n",
    "    # Initialize some sample objects we will need\n",
    "    input_samples = sample.sample_set(input_dim)\n",
    "    output_samples = sample.sample_set(output_dim)\n",
    "\n",
    "    # Choose random samples in parameter space to solve the model\n",
    "    domain_min, domain_max = 0, 1\n",
    "    input_samples.set_values(np.random.uniform(domain_min, domain_max, \n",
    "                                [np.int(num_samples), input_dim]))\n",
    "    input_samples.set_domain(np.array([[domain_min, domain_max] \n",
    "                                for _ in range(input_dim)]))\n",
    "    \n",
    "    # Make the MC assumption and compute the volumes of each voronoi cell\n",
    "    input_samples.estimate_volume_mc()\n",
    "\n",
    "\n",
    "    # Compute the output values with the map Q\n",
    "    output_samples.set_values(Q.dot(input_samples.get_values().transpose()).\\\n",
    "            transpose())\n",
    "\n",
    "    # Calculate the gradient vectors at some subset of the samples.  Here the\n",
    "    # *normalize* argument is set to *True* because we are using bin_ratio to\n",
    "    # determine the uncertainty in our data.\n",
    "    cluster_discretization = sample.discretization(input_samples, output_samples)\n",
    "    # We will approximate the jacobian at each of the centers\n",
    "    center_discretization = grad.calculate_gradients_rbf(cluster_discretization,\n",
    "            num_centers, normalize=True)\n",
    "\n",
    "    return input_samples, output_samples, center_discretization, Q\n",
    "\n",
    "\n",
    "\n",
    "def solve_problem(my_discretization, Q_ref, QoI_indices, percentile = 1.0, measure=True):\n",
    "    input_samples = my_discretization.get_input_sample_set()\n",
    "    output_samples = my_discretization.get_output_sample_set()\n",
    "    # Choose some QoI indices to solve the inverse problem with\n",
    "    output_samples._dim = len(QoI_indices)\n",
    "    output_samples.set_values(output_samples.get_values()[:, QoI_indices])\n",
    "    \n",
    "    # bin_ratio defines the uncertainty in our data\n",
    "    # Define the level of uncertainty in the measured reference datum\n",
    "    uncertainty = rect_scale = bin_ratio = 0.25\n",
    "\n",
    "    # Make the MC assumption and compute the volumes of each voronoi cell\n",
    "    input_samples.estimate_volume_mc()\n",
    "    \n",
    "    # Find the simple function approximation\n",
    "    if measure:\n",
    "        simpleFunP.regular_partition_uniform_distribution_rectangle_size(\n",
    "            data_set=my_discretization, Q_ref=Q_ref, rect_size=uncertainty,\n",
    "            cells_per_dimension=1)\n",
    "    else:\n",
    "        simpleFunP.regular_partition_uniform_distribution_rectangle_scaled(\n",
    "            data_set=my_discretization, Q_ref=Q_ref, rect_scale=uncertainty,\n",
    "            cells_per_dimension=1)\n",
    "    \n",
    "    \n",
    "    # Calculate probablities making the Monte Carlo assumption\n",
    "    calculateP.prob(my_discretization)\n",
    "    \n",
    "    # Sort samples by highest probability density and find how many samples lie in\n",
    "    # the support of the inverse solution.  With the Monte Carlo assumption, this\n",
    "    # also tells us the approximate volume of this support.\n",
    "    (num_samples, _, indices_in_inverse) =\\\n",
    "        postTools.sample_highest_prob(top_percentile=percentile,\n",
    "        sample_set=input_samples, sort=True)\n",
    "    \n",
    "    # Print the approximate percentage of the measure of the parameter space defined\n",
    "    # by the support of the inverse density\n",
    "    if comm.rank == 0:\n",
    "        print('The approximate percentage of the measure of the parameter space defined')\n",
    "        print('by the support of the inverse density associated with the choice of QoI map is')\n",
    "        print('%2.4f%%  with '%(100*np.sum(input_samples.get_volumes()[indices_in_inverse])), \n",
    "              num_samples, ' samples.')\n",
    "\n",
    "    return num_samples, indices_in_inverse\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# Suggested Changes \n",
    "\n",
    "## Example 1: `linear_measure_binsize_large.py` \n",
    "> Objective: achieve the smallest support of the inverse solution, assuming we define the uncertainty in our data to be fixed, i.e., independent of the range of data measured for each QoI (`bin_size`).\n",
    "- `independent_error` = `True`\n",
    "- `measure` = `True`\n",
    "- (optional): set `output_dim` = 100 to leverage keyword arguments that optimize computations.\n",
    "\n",
    "## Example 2: `linear_measure_binratio.py`\n",
    "> Objective: achieve the smallest support of the inverse solution, assuming we define the uncertainty in our data to be relative to the range of the data for each QoI (`bin_ratio`).\n",
    "- `independent_error` = `False`\n",
    "- `measure` = `True`\n",
    "\n",
    "## Example 3: `linear_skewness_binratio.py`\n",
    ">  Objective: optimal skewness properties which will yield an inverse solution that can be approximated well on the implicitly-defined Borel sets (Voronoi cells) that constitute parameter space. \n",
    "The uncertainty in our data is relative to the range of data measured in each QoI (`bin_ratio`), but can be changed with \n",
    "- `independent_error` = `False`\n",
    "- `measure` = `False`\n",
    "> By optimizing for our ability to approximate sets in our parameter space, we can expect much less precision on average in the solution to a given inverse problem.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ MAKE SELECTION ############\n",
    "independent_error = True # is the uncertainty in the data independent of the range of the data?\n",
    "measure = True # if True, optimize w/r/t the size of the inverse set (expected scaling effect)\n",
    "########################################\n",
    "\n",
    "# Set up the info for the spaces\n",
    "num_samples = 1E5\n",
    "num_centers = 10\n",
    "\n",
    "# feel free to change the following, but ideally, keep input_dim <= output_dim\n",
    "input_dim = 5\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0) # (optional) set seed for repeatable results.\n",
    "input_samples, output_samples, center_discretization, Q = \\\n",
    "        initialize_problem(input_dim, output_dim, num_samples, num_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these gradient vectors, we are now ready to choose an optimal set of QoIs to use in the inverse problem, based on minimizing the support of the inverse solution (measure).  \n",
    "\n",
    "The most robust method for this is `bet.sensitivity.chooseQoIs.chooseOptQoIs_large` which returns the best set of 2, (3, 4 ... until `input_dim`).  This method returns a list of matrices.  Each matrix has 10 rows, the first column representing the expected inverse measure ratio, and the rest of the columns the corresponding QoI indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.27257026 3.         6.        ]\n",
      " [4.34105947 3.         4.        ]\n",
      " [4.43961888 3.         9.        ]] \n",
      "\n",
      "[[11.55460603  3.          6.          9.        ]\n",
      " [14.26945967  3.          6.          8.        ]\n",
      " [14.37424713  6.          8.          9.        ]] \n",
      "\n",
      "[[41.39727768  3.          6.          8.          9.        ]\n",
      " [59.10273955  2.          3.          8.          9.        ]\n",
      " [64.74186687  3.          4.          8.          9.        ]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_samples_center = center_discretization.get_input_sample_set()\n",
    "\n",
    "num_best_sets = 3 # what is the worst-ranked option you want to investigate?\n",
    "\n",
    "if output_dim > 50: # optional tolerances for large problems (output space dimension)\n",
    "    best_sets = cqoi.chooseOptQoIs_large(input_samples_center, measure=measure,\n",
    "                            max_qois_return=5, num_optsets_return=num_best_sets, \n",
    "                            inner_prod_tol=0.9, measskew_tol=1E2)\n",
    "else:\n",
    "    best_sets = cqoi.chooseOptQoIs_large(input_samples_center, measure=measure, \n",
    "                            num_optsets_return=num_best_sets)\n",
    "\n",
    "for i in range(num_best_sets):\n",
    "    print(best_sets[i], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number in the first column represents the expected volume of the inverse image of a unit hypercube in the data space if `measure=True`, and it is the expected skewness if `measure=False`.\n",
    "\n",
    "With the `independent_error` definition of the uncertainty in the data, here we expect to see inverse solutions that have a smaller support (expected inverse measure ratio < 1 or 2) than the original volume of the hypercube in the data space (which we nominally set to `0.25` in `solve_problem` above... you are welcome to change it).\n",
    "\n",
    "This interpretation of the expected volume ratios is only valid for inverting from a data space that has the same dimensions as the parameter space. \n",
    "When inverting into a higher dimensional space, this expected volume ratio is the expected volume of the cross section of the inverse solution.\n",
    "\n",
    "---\n",
    "\n",
    "At this point we have determined the optimal set of QoIs to use in the inverse problem.  \n",
    "Now we compare the support of the inverse solution using different sets of these QoIs. \n",
    "We set `Q_ref` to correspond to the output from the parameter taken to be in the center of the parameter space.\n",
    "We choose the set of QoIs to consider below, both _how many_ and _how optimal_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your QoI sub-indices selection:  [3 6]\n"
     ]
    }
   ],
   "source": [
    "############ MAKE SELECTION ############\n",
    "num_qoi = 2 # select the number of quantities of interest\n",
    "ranking_selection = 1 # select your choice (1st, 2nd, 3rd) best (start at 1)\n",
    "########################################\n",
    "\n",
    "QoI_indices = best_sets[num_qoi-2][ranking_selection-1, 1:].astype(int) # Chooses the optimal set of 2 QoI\n",
    "print(\"Your QoI sub-indices selection: \", QoI_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The approximate percentage of the measure of the parameter space defined\n",
      "by the support of the inverse density associated with the choice of QoI map is\n",
      "7.1840%  with  7184  samples.\n"
     ]
    }
   ],
   "source": [
    "# Create discretization object and solve problem\n",
    "my_discretization = sample.discretization(input_sample_set=input_samples,\n",
    "                                        output_sample_set=output_samples)\n",
    "\n",
    "# Define the reference point in the output space to correspond to the center of the input space.\n",
    "param_ref = 0.5 * np.ones(input_dim)\n",
    "Q_ref = Q[QoI_indices, :].dot(param_ref)\n",
    "\n",
    "num_samples, indices_in_inverse = solve_problem(my_discretization, Q_ref, QoI_indices, \n",
    "                                                measure=measure, percentile=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'my_discretization' (discretization)\n",
      "Stored 'param_ref' (ndarray)\n",
      "Stored 'Q_ref' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store my_discretization\n",
    "%store param_ref\n",
    "%store Q_ref"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
